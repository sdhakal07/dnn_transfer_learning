{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a768da4a-5344-48e0-97f1-2efcf309219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffacc29e-5a51-4e5f-93f7-876ee9fc692c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: cane - 4863 images found\n",
      "Processing category: cavallo - 2623 images found\n",
      "Processing category: elefante - 1446 images found\n",
      "Processing category: farfalla - 2112 images found\n",
      "Processing category: gallina - 3098 images found\n",
      "Processing category: gatto - 1668 images found\n",
      "Processing category: mucca - 1866 images found\n",
      "Processing category: pecora - 1820 images found\n",
      "Processing category: ragno - 4821 images found\n",
      "Processing category: scoiattolo - 1862 images found\n",
      "Data successfully split into training and validation sets!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define paths\n",
    "original_dataset_dir = r\"animal\\raw-img\"\n",
    "base_dir = r\"C:\\Users\\Leapfrog\\Desktop\\Others\\Mtech AI\\DNN\\Assignment 2\"\n",
    "\n",
    "# Create directories for training and validation splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through each category (class) in the raw-img directory\n",
    "for category in os.listdir(original_dataset_dir):\n",
    "    category_dir = os.path.join(original_dataset_dir, category)\n",
    "    \n",
    "    # Ensure category_dir is a directory\n",
    "    if os.path.isdir(category_dir):\n",
    "        images = [f for f in os.listdir(category_dir) if os.path.isfile(os.path.join(category_dir, f))]\n",
    "        \n",
    "        # Debugging: Print out the number of images found\n",
    "        print(f\"Processing category: {category} - {len(images)} images found\")\n",
    "\n",
    "        # Skip this category if there are no images\n",
    "        if len(images) == 0:\n",
    "            print(f\"No images found in {category}, skipping this category.\")\n",
    "            continue\n",
    "        \n",
    "        # Split the images into training and validation sets\n",
    "        train_images, validation_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Create category directories in train and validation folders\n",
    "        train_category_dir = os.path.join(train_dir, category)\n",
    "        os.makedirs(train_category_dir, exist_ok=True)\n",
    "        validation_category_dir = os.path.join(validation_dir, category)\n",
    "        os.makedirs(validation_category_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy the images\n",
    "        for image in train_images:\n",
    "            src = os.path.join(category_dir, image)\n",
    "            dst = os.path.join(train_category_dir, image)\n",
    "            shutil.copy2(src, dst)\n",
    "        \n",
    "        for image in validation_images:\n",
    "            src = os.path.join(category_dir, image)\n",
    "            dst = os.path.join(validation_category_dir, image)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "print(\"Data successfully split into training and validation sets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fd7042-2cba-4bca-994b-fe53542ee01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16755 images belonging to 10 classes.\n",
      "Found 1044 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Image data generator for loading images\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.2)\n",
    "\n",
    "# Load dataset from directory\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    r\"train\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    r\"validation\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074cbc3-fc16-4351-8d7a-76505d378ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 0us/step\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leapfrog\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1221s\u001b[0m 2s/step - accuracy: 0.5478 - loss: 2.4052 - val_accuracy: 0.7902 - val_loss: 0.6525\n",
      "Epoch 2/5\n",
      "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1290s\u001b[0m 2s/step - accuracy: 0.7486 - loss: 0.7351 - val_accuracy: 0.8324 - val_loss: 0.5297\n",
      "Epoch 3/5\n",
      "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1368s\u001b[0m 3s/step - accuracy: 0.8027 - loss: 0.5847 - val_accuracy: 0.8314 - val_loss: 0.5392\n",
      "Epoch 4/5\n",
      "\u001b[1m404/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5:17\u001b[0m 3s/step - accuracy: 0.7997 - loss: 0.5683"
     ]
    }
   ],
   "source": [
    "# Load the VGG16 model without the top layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of VGG16\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of VGG16\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=validation_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b61299-274b-45c0-8f9d-5bc9970e2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Plotting accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plotting loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f872949a-1b06-42d1-bebd-c8a18d626323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3045s\u001b[0m 6s/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 5s/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features from the training data using the trained model\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.layers[-3].output)  # Output from the dense layer before softmax\n",
    "\n",
    "train_features = feature_extractor.predict(train_generator)\n",
    "train_labels = train_generator.classes\n",
    "\n",
    "# Flatten the features for SVM\n",
    "train_features = train_features.reshape(train_features.shape[0], -1)\n",
    "\n",
    "# Extract features from the validation data\n",
    "validation_features = feature_extractor.predict(validation_generator)\n",
    "validation_labels = validation_generator.classes\n",
    "\n",
    "# Flatten the features for SVM\n",
    "validation_features = validation_features.reshape(validation_features.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf491f-3e1a-45a1-9d05-7f9fce79fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model\n",
    "svm.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215aa9d3-78e6-495a-aa88-94bd1f5c86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the SVM classifier\n",
    "y_pred = svm.predict(validation_features)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(validation_labels, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(validation_labels, y_pred, target_names=validation_generator.class_indices.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a3155-9ba4-41ef-8f16-7b010e4047c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
